{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Embedding, Flatten, Dense, Concatenate\n",
    "import functions as f\n",
    "\n",
    "# Veriyi yükle\n",
    "train = pd.read_parquet('train_final.parquet') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(['month'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full = train.drop(['target'], axis=1)\n",
    "y_train_full = train['target']\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, test_size=0.1, random_state=42)\n",
    "\n",
    "X_train_ids = X_train['id']\n",
    "X_valid_ids = X_valid['id']\n",
    "\n",
    "cat_train = X_train[['carrier', 'devicebrand']]\n",
    "cat_train = pd.get_dummies(cat_train)\n",
    "\n",
    "cat_valid = X_valid[['carrier', 'devicebrand']]\n",
    "cat_valid = pd.get_dummies(cat_valid)\n",
    "\n",
    "X_train = X_train.drop(['id','carrier', 'devicebrand'], axis=1)\n",
    "X_valid = X_valid.drop(['id','carrier', 'devicebrand'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "mlb.fit([['1', '2', '3','4', '5', '6','7', '8', '9']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = mlb.transform(y_train)\n",
    "y_valid = mlb.transform(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class DLRM(tf.keras.Model):\n",
    "    def __init__(self, num_dense_features, num_sparse_features, embedding_dim):\n",
    "        super(DLRM, self).__init__()\n",
    "        # Sürekli özellikler için çok katmanlı algılayıcı (MLP)\n",
    "        self.dense_mlp = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(256, activation='relu'),\n",
    "            tf.keras.layers.Dense(128, activation='relu'),\n",
    "            tf.keras.layers.Dense(64, activation='relu')\n",
    "        ])\n",
    "        \n",
    "        # Kategorik özellikler için embedding tabloları\n",
    "        self.embeddings = [tf.keras.layers.Embedding(100, embedding_dim) for _ in range(num_sparse_features)]\n",
    "        \n",
    "        # Üst MLP\n",
    "        self.top_mlp = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(128, activation='relu'),\n",
    "            tf.keras.layers.Dense(64, activation='relu'),\n",
    "            tf.keras.layers.Dense(9, activation='softmax')\n",
    "        ])\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        dense_x, sparse_x = inputs\n",
    "        # Sürekli özellikleri işle\n",
    "        dense_out = self.dense_mlp(dense_x)\n",
    "        \n",
    "        # Kategorik özellikleri işle\n",
    "        sparse_out = [emb(sparse_x[:, i]) for i, emb in enumerate(self.embeddings)]\n",
    "        sparse_out = tf.concat(sparse_out, axis=1)\n",
    "        \n",
    "        # Sürekli ve kategorik özellikleri birleştir\n",
    "        x = tf.concat([dense_out, sparse_out], axis=1)\n",
    "        \n",
    "        # Üst MLP\n",
    "        out = self.top_mlp(x)\n",
    "        \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "\n",
    "num_dense_features = len(X_train.columns) #53\n",
    "num_sparse_features = len(cat_train.columns) #620\n",
    "embedding_dim = 31\n",
    "\n",
    "\n",
    "# Modeli oluşturun\n",
    "model = DLRM(num_dense_features, num_sparse_features, embedding_dim)\n",
    "\n",
    "# Modeli derleyin\n",
    "model.compile(optimizer=Adam(), loss=BinaryCrossentropy())\n",
    "\n",
    "# Modeli eğitin\n",
    "model.fit([X_train, cat_train], [y_train], epochs=10, batch_size=32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model_saved\", save_format=\"tf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eksik sütunları bulun\n",
    "missing_cols = set(cat_train.columns) - set(cat_valid.columns)\n",
    "\n",
    "# Eksik sütunları 'cat_valid' DataFrame'ine ekleyin\n",
    "for c in missing_cols:\n",
    "    cat_valid[c] = 0\n",
    "\n",
    "# Sütunları 'cat_train' ile aynı sırayla düzenleyin\n",
    "cat_valid = cat_valid[cat_train.columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Modelin performansını değerlendirin\n",
    "y_pred = model.predict([X_valid, cat_valid])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "class_names = ['1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "\n",
    "# En yüksek 3 olasılığa sahip sınıfların indekslerini bulun\n",
    "top3_classes = np.argsort(y_pred, axis=1)[:, -3:]\n",
    "\n",
    "# Indeksleri sınıf isimleriyle değiştirin\n",
    "top3_class_names = [[class_names[i] for i in indices] for indices in top3_classes]\n",
    "\n",
    "# MultiLabelBinarizer'ı oluşturun\n",
    "mlb = MultiLabelBinarizer()\n",
    "mlb.fit([['1', '2', '3', '4', '5', '6', '7', '8', '9']])\n",
    "\n",
    "# Tahminleri çoklu etiketli bir biçime dönüştürün\n",
    "y_pred_transformed = mlb.transform(top3_class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_transformed[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaccard = f.jaccard_similarity_score(y_valid, y_pred_transformed)\n",
    "jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veriyi yükle\n",
    "Test = pd.read_parquet('test_final.parquet') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test = Test.drop(['month'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_ids = Test['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test = Test.drop(['id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_Test = Test[['carrier', 'devicebrand']]\n",
    "cat_Test = pd.get_dummies(cat_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test = Test.drop(['carrier', 'devicebrand'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eksik sütunları bulun\n",
    "missing_cols = set(cat_train.columns) - set(cat_Test.columns)\n",
    "\n",
    "# Eksik sütunları 'cat_valid' DataFrame'ine ekleyin\n",
    "for c in missing_cols:\n",
    "    cat_Test[c] = 0\n",
    "\n",
    "# Sütunları 'cat_train' ile aynı sırayla düzenleyin\n",
    "cat_Test = cat_Test[cat_train.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_y_pred = model.predict([Test, cat_Test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veriyi yükle\n",
    "ssf = pd.read_parquet('submission_sample_final.parquet') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_y_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En yüksek 3 olasılığa sahip sınıfların indekslerini bulun\n",
    "top3_classes = np.argsort(Test_y_pred, axis=1)[:, -3:]\n",
    "\n",
    "# Indeksleri sınıf isimleriyle değiştirin\n",
    "top3_class_names = [[class_names[i] for i in indices] for indices in top3_classes]\n",
    "\n",
    "# MultiLabelBinarizer'ı oluşturun\n",
    "mlb = MultiLabelBinarizer()\n",
    "mlb.fit([['1', '2', '3', '4', '5', '6', '7', '8', '9']])\n",
    "\n",
    "# Tahminleri çoklu etiketli bir biçime dönüştürün\n",
    "Test_y_pred_transformed = mlb.transform(top3_class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_y_pred_transformed[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Her bir NumPy dizisini stringe dönüştürün\n",
    "str_list = [''.join(map(str, arr)) for arr in Test_y_pred_transformed]\n",
    "\n",
    "str_list  # Çıktı: ['010001010', '000101010']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tahminleri içeren yeni bir veri çerçevesi oluşturun\n",
    "tahmin_verisi = pd.DataFrame({'id': Test_ids, 'target': str_list})\n",
    "\n",
    "# Tahmin verisini CSV dosyasına kaydedin\n",
    "tahmin_verisi.to_csv('ilk_dlrm.csv', index=False, columns=['id', 'target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tahmin_verisi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
